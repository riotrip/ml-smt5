{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNV/u+AQSYssPNlJRKOKarM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riotrip/ml-smt5/blob/main/LAT_JS13.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rio Tri Prayogo - 2341720236 - TI 3F/25**\n",
        "---\n",
        "## **JS13 - Artificial Neural Network**"
      ],
      "metadata": {
        "id": "m95wZ_CV-TYJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lab 1**\n",
        "\n",
        "Klasifikasi Bunga Iris dengan Perceptron"
      ],
      "metadata": {
        "id": "lQlFymIN-cz7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UMZTl7DC8NiJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/PembelajaranMesin_Rio/docs/iris.csv', header=None)\n",
        "setosa = df[df[4] == 'Iris-setosa']\n",
        "versicolor = df[df[4] == 'Iris-versicolor']\n",
        "virginica = df[df[4] == 'Iris-virginica']\n",
        "\n",
        "a, b = 0, 3\n",
        "plt.scatter(setosa[a], setosa[b], color='red', marker='o', label='setosa')\n",
        "plt.scatter(versicolor[a], versicolor[b], color='blue', marker='x', label='versicolor')\n",
        "\n",
        "plt.xlabel('Petal Length')\n",
        "plt.ylabel('Sepal Length')\n",
        "plt.legend(loc='upper left')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3iMercec_OhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Perceptron(object):\n",
        "    def __init__(self, eta=0.01, n_iter=10):\n",
        "        self.eta = eta\n",
        "        self.n_iter = n_iter\n",
        "\n",
        "    def fit(self, X, y):\n",
        "\n",
        "        self.w_ = np.zeros(1 + X.shape[1])\n",
        "        self.errors_ = []\n",
        "\n",
        "        for _ in range(self.n_iter):\n",
        "            errors = 0\n",
        "            for xi, target in zip(X, y):\n",
        "                update = self.eta * (target - self.predict(xi))\n",
        "                self.w_[0] += update\n",
        "                self.w_[1:] += update * xi\n",
        "                errors += int(update != 0.0)\n",
        "            self.errors_.append(errors)\n",
        "        return self\n",
        "\n",
        "    def net_input(self, X):\n",
        "        return np.dot(X, self.w_[1:]) + self.w_[0]\n",
        "\n",
        "    def predict(self, X):\n",
        "        return np.where(self.net_input(X) >= 0.0, 1, -1)"
      ],
      "metadata": {
        "id": "hldlYCXU_RQC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = df.iloc[0:100, 4].values # pilih 100 data awal\n",
        "y = np.where(y == 'Iris-setosa', -1, 1) # ganti coding label\n",
        "X = df.iloc[0:100, [0, 3]].values # slice data latih"
      ],
      "metadata": {
        "id": "ZWW7uLBG_TQv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppn = Perceptron(eta=0.1, n_iter=10)\n",
        "ppn.fit(X, y)"
      ],
      "metadata": {
        "id": "Rz3B8exF_Utb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(1, len(ppn.errors_)+1), ppn.errors_)\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Number of updates')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nTvlZ9nI_WeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# buat fungsi untuk plot decision region\n",
        "\n",
        "from matplotlib.colors import ListedColormap\n",
        "\n",
        "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
        "    # setup marker generator and color map\n",
        "    markers = ('s', 'x', 'o', '^', 'v')\n",
        "    colors = ('r', 'b', 'g', 'k', 'grey')\n",
        "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
        "\n",
        "    # plot the decision regions by creating a pair of grid arrays xx1 and xx2 via meshgrid function in Numpy\n",
        "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
        "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
        "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution), np.arange(x2_min, x2_max, resolution))\n",
        "\n",
        "    # use predict method to predict the class labels z of the grid points\n",
        "    Z = classifier.predict(np.array([xx1.ravel(),xx2.ravel()]).T)\n",
        "    Z = Z.reshape(xx1.shape)\n",
        "\n",
        "    # draw the contour using matplotlib\n",
        "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
        "    plt.xlim(xx1.min(), xx1.max())\n",
        "    plt.ylim(xx2.min(), xx2.max())\n",
        "\n",
        "    # plot class samples\n",
        "    for i, cl in enumerate(np.unique(y)):\n",
        "        plt.scatter(x=X[y==cl, 0], y=X[y==cl, 1], alpha=0.8, c=cmap(i), marker=markers[i], label=cl)"
      ],
      "metadata": {
        "id": "qJemTA52_YOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lab 2**\n",
        "\n",
        "Nilai Logika XOR dengan MLP"
      ],
      "metadata": {
        "id": "IRQ_tF0R_bQT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier"
      ],
      "metadata": {
        "id": "Ax55xA90_gKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = [0, 1, 1, 0] # label\n",
        "X = [[0, 0], [0, 1], [1, 0], [1, 1]] # data"
      ],
      "metadata": {
        "id": "FD_egS5c_jC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit model\n",
        "clf = MLPClassifier(solver='lbfgs', activation='logistic', hidden_layer_sizes=(2,), max_iter=100, random_state=20)\n",
        "clf.fit(X, y)"
      ],
      "metadata": {
        "id": "ekbqxgA2_kOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = clf.predict(X)\n",
        "print('Accuracy: %s' % clf.score(X, y))\n",
        "for i,p in enumerate(pred[:10]):\n",
        "    print('True: %s, Predicted: %s' % (y[i], p))"
      ],
      "metadata": {
        "id": "CTVwszEv_lhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lab 3**\n",
        "\n",
        "Klasifikasi Churn Rate dengan ANN"
      ],
      "metadata": {
        "id": "5A10B69Z_nPN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "r8-QsUS8_vA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/PembelajaranMesin_Rio/docs/Churn_Modelling.csv')\n",
        "X = dataset.iloc[:, 3:-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "metadata": {
        "id": "Znwa7U3Y_wMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X)"
      ],
      "metadata": {
        "id": "Jm8jFlcc_xmr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "X[:, 2] = le.fit_transform(X[:, 2])"
      ],
      "metadata": {
        "id": "02N_AiuC_zWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [1])], remainder='passthrough')\n",
        "X = np.array(ct.fit_transform(X))"
      ],
      "metadata": {
        "id": "5yqxes_S_2Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
      ],
      "metadata": {
        "id": "YMR3N1WD_4KL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "h6f7n_9g_6bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "0l93JGEL_7D2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "1zEv9uAE_94U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=6, activation='relu'))"
      ],
      "metadata": {
        "id": "Fcc5Yccw_-nn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "uS2VxU7SABXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "d84-znICAGeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ann.fit(X_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "metadata": {
        "id": "u5m6QJJaAIBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(ann.predict(sc.transform([[1, 0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])) > 0.5)"
      ],
      "metadata": {
        "id": "FmVnUjikAKqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = ann.predict(X_test)\n",
        "y_pred = (y_pred > 0.5)\n",
        "print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))"
      ],
      "metadata": {
        "id": "D5c9xfDqAMFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "CvS79q7IANqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Lab 4\n",
        "\n",
        "Klasifikasi Siang dan Malam dengan ANN"
      ],
      "metadata": {
        "id": "MutxiJNjAPIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "from skimage.feature import hog\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ],
      "metadata": {
        "id": "hXK1RPlbAUCL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images and labels from a directory structure\n",
        "def load_dataset(img_dir):\n",
        "    p = Path(img_dir)\n",
        "    img_list = []\n",
        "    for folder in p.glob('*'):\n",
        "        label = folder.name\n",
        "        for file in folder.glob('*.jpg'):\n",
        "            img = cv2.imread(str(file))\n",
        "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "            img_list.append((img, label))\n",
        "    return img_list\n",
        "\n",
        "train_dir = \"images/training/\"\n",
        "test_dir  = \"images/test/\"\n",
        "\n",
        "train_img = load_dataset(train_dir)\n",
        "test_img  = load_dataset(test_dir)"
      ],
      "metadata": {
        "id": "tOM6uox4AWGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess images: resize and encode labels\n",
        "def resize_image(img, size=(256,256)):\n",
        "    return cv2.resize(img, size)\n",
        "\n",
        "def label_encoder(label):\n",
        "    return 1 if label == 'day' else 0\n",
        "\n",
        "def preprocess(img_list):\n",
        "    X = []\n",
        "    y = []\n",
        "    for img, label in img_list:\n",
        "        img_std = resize_image(img)\n",
        "        X.append(img_std)\n",
        "        y.append(label_encoder(label))\n",
        "    return X, y\n",
        "\n",
        "X_train_img, y_train = preprocess(train_img)\n",
        "X_test_img,  y_test  = preprocess(test_img)"
      ],
      "metadata": {
        "id": "sf4wAs3gAYyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract HOG features\n",
        "def extract_hog(X_imgs):\n",
        "    feats = []\n",
        "    for img in X_imgs:\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "        hog_feat = hog(gray,\n",
        "                       orientations=9,\n",
        "                       pixels_per_cell=(8,8),\n",
        "                       cells_per_block=(2,2),\n",
        "                       block_norm='L2-Hys',\n",
        "                       visualize=False,\n",
        "                       feature_vector=True)\n",
        "        feats.append(hog_feat)\n",
        "    return np.array(feats)\n",
        "\n",
        "X_train_feat = extract_hog(X_train_img)\n",
        "X_test_feat  = extract_hog(X_test_img)"
      ],
      "metadata": {
        "id": "lZGX45WwAbAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_feat)\n",
        "X_test_scaled  = scaler.transform(X_test_feat)"
      ],
      "metadata": {
        "id": "fXAV8Pr-AcnM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_scaled, y_train,\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Convert label ke numpy array\n",
        "y_train = np.array(y_train)\n",
        "y_val   = np.array(y_val)\n",
        "y_test  = np.array(y_test)"
      ],
      "metadata": {
        "id": "OHu4jjvDAdyi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(input_dim,)),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "ivUUXatMAfcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_data=(X_val, y_val)\n",
        ")"
      ],
      "metadata": {
        "id": "qRCSzhKWAiFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_acc = model.evaluate(X_test_scaled, y_test)\n",
        "print(\"Akurasi Test:\", test_acc)"
      ],
      "metadata": {
        "id": "WvEAXFOVAjab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_prob = model.predict(X_test_scaled)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "id": "egRfflEiAlDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'], label='Train Acc')\n",
        "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dZgNmvJTAnKO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('day_night_classifier_model.h5')"
      ],
      "metadata": {
        "id": "pqkXCZ-yApCk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}