{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1yVf31l2_7BECrN7f2jdjW62cT_JCKkRd",
      "authorship_tag": "ABX9TyM9G1J2cEoitL8VeX2NSbBG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riotrip/ml-smt5/blob/main/TG1_2_JS07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Rio Tri Prayogo - 2341720236 - TI 3F/25**\n",
        "---\n",
        "## **JS07 - Approximate Nearest Neighbors (ANN)**"
      ],
      "metadata": {
        "id": "WmG1ueuvKpWc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tugas 1**\n",
        "Lakukan percobaan pada metric distance yang berbeda, 1000 vs 1.000.000 data, 2D vs 5D data, untuk algoritma,\n",
        "\n",
        "a. ANNOY\n",
        "\n",
        "b. FAISS\n",
        "\n",
        "c. HNSW\n",
        "\n",
        "Catat performansinya dalam bentuk tabel, misa"
      ],
      "metadata": {
        "id": "ZAhEvTJVKwPw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install ANNOY\n",
        "!pip install annoy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5pKBUxTNn9B",
        "outputId": "79465d1b-dcc4-4889-e283-5654a0d8139a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting annoy\n",
            "  Downloading annoy-1.17.3.tar.gz (647 kB)\n",
            "\u001b[?25l     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m0.0/647.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m647.5/647.5 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.3-cp312-cp312-linux_x86_64.whl size=551807 sha256=21f5cbf1c15042fb7386faf545f4e3cbd84b4f40f61318eef40c095da2ce782e\n",
            "  Stored in directory: /root/.cache/pip/wheels/db/b9/53/a3b2d1fe1743abadddec6aa541294b24fdbc39d7800bc57311\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install FAISS\n",
        "!pip install faiss-cpu\n",
        "!pip install faiss-gpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ip6vqQNGN9U5",
        "outputId": "31531703-74a0-4892-ada6-b19ef0fe6a56"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install HNSW\n",
        "!pip install hnswlib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXv0atGAOEP3",
        "outputId": "32a3778d-7cf8-40e1-e51e-0a9ec5848552"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hnswlib\n",
            "  Downloading hnswlib-0.8.0.tar.gz (36 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from hnswlib) (2.0.2)\n",
            "Building wheels for collected packages: hnswlib\n",
            "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hnswlib: filename=hnswlib-0.8.0-cp312-cp312-linux_x86_64.whl size=2528146 sha256=607c72f4ee5f1024bd4b3045d487015b8eba69d0c270a50b07a93bd2725f6d28\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/39/b3/cbd7f9cbb76501d2d5fbc84956e70d0b94e788aac87bda465e\n",
            "Successfully built hnswlib\n",
            "Installing collected packages: hnswlib\n",
            "Successfully installed hnswlib-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdb9jch2nlRm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea9e31af-4605-4695-aefc-8810ea52b9d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== EKSPERIMEN PERBANDINGAN PERFORMANCE ANN, FAISS, HNSW ===\n",
            "\n",
            "Testing: 1,000 data, 2D\n",
            "  Running Annoy...\n",
            "  Running FAISS...\n",
            "  Running HNSW...\n",
            "  Completed: 1,000 data, 2D\n",
            "\n",
            "Testing: 1,000 data, 5D\n",
            "  Running Annoy...\n",
            "  Running FAISS...\n",
            "  Running HNSW...\n",
            "  Completed: 1,000 data, 5D\n",
            "\n",
            "Testing: 1,000,000 data, 2D\n",
            "  Running Annoy...\n",
            "  Running FAISS...\n",
            "  Running HNSW...\n",
            "  Completed: 1,000,000 data, 2D\n",
            "\n",
            "Testing: 1,000,000 data, 5D\n",
            "  Running Annoy...\n",
            "  Running FAISS...\n",
            "  Running HNSW...\n",
            "  Completed: 1,000,000 data, 5D\n",
            "\n",
            "================================================================================\n",
            "HASIL PERBANDINGAN PERFORMANCE\n",
            "================================================================================\n",
            "\n",
            "BUILD TIME (detik):\n",
            "Jumlah Data/Dimensi    ANNOY   FAISS      HNSW\n",
            "           1,000/2D  0.0214s 0.0001s   0.0468s\n",
            "           1,000/5D  0.0144s 0.0000s   0.0537s\n",
            "       1,000,000/2D 27.6529s 0.0026s 102.4016s\n",
            "       1,000,000/5D 22.9693s 0.0146s 169.9104s\n",
            "\n",
            "QUERY TIME (detik):\n",
            "Jumlah Data/Dimensi     ANNOY     FAISS      HNSW\n",
            "           1,000/2D 0.000079s 0.000052s 0.000057s\n",
            "           1,000/5D 0.000058s 0.000043s 0.000057s\n",
            "       1,000,000/2D 0.000106s 0.005454s 0.000088s\n",
            "       1,000,000/5D 0.000115s 0.006081s 0.000410s\n",
            "\n",
            "================================================================================\n",
            "ANALISIS:\n",
            "================================================================================\n",
            "\n",
            "Konfigurasi: 1,000/2D\n",
            "Build Time Tercepat: 0.0001s\n",
            "Query Time Tercepat: 0.000052s\n",
            "5 Neighbor Teratas:\n",
            "  Annoy: [112, 535, 777, 246, 763]\n",
            "  FAISS: [112 535 777 246 763]\n",
            "  HNSW:  [112 535 777 246 763]\n",
            "\n",
            "Konfigurasi: 1,000/5D\n",
            "Build Time Tercepat: 0.0000s\n",
            "Query Time Tercepat: 0.000043s\n",
            "5 Neighbor Teratas:\n",
            "  Annoy: [988, 780, 27, 943, 93]\n",
            "  FAISS: [988 780  27 943  93]\n",
            "  HNSW:  [988 780  27 943  93]\n",
            "\n",
            "Konfigurasi: 1,000,000/2D\n",
            "Build Time Tercepat: 0.0026s\n",
            "Query Time Tercepat: 0.000088s\n",
            "5 Neighbor Teratas:\n",
            "  Annoy: [132774, 119034, 511191, 482199, 913140]\n",
            "  FAISS: [132774 119034 511191 482199 913140]\n",
            "  HNSW:  [132774 119034 511191 482199 913140]\n",
            "\n",
            "Konfigurasi: 1,000,000/5D\n",
            "Build Time Tercepat: 0.0146s\n",
            "Query Time Tercepat: 0.000115s\n",
            "5 Neighbor Teratas:\n",
            "  Annoy: [901095, 495168, 561017, 163986, 185734]\n",
            "  FAISS: [901095 495168 561017 163986 185734]\n",
            "  HNSW:  [901095 495168 561017 163986 185734]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import time\n",
        "from annoy import AnnoyIndex\n",
        "import faiss\n",
        "import hnswlib\n",
        "import pandas as pd\n",
        "\n",
        "def benchmark_annoy(X, query, k, dim, n_trees=10):\n",
        "    \"\"\"Benchmark Annoy dengan Euclidean distance\"\"\"\n",
        "    ann_index = AnnoyIndex(dim, 'euclidean')\n",
        "\n",
        "    start = time.time()\n",
        "    for i in range(len(X)):\n",
        "        ann_index.add_item(i, X[i])\n",
        "    ann_index.build(n_trees)\n",
        "    build_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    neighbors = ann_index.get_nns_by_vector(query[0], k, include_distances=True)\n",
        "    query_time = time.time() - start\n",
        "\n",
        "    return build_time, query_time, neighbors[0][:5]\n",
        "\n",
        "def benchmark_faiss(X, query, k, dim):\n",
        "    \"\"\"Benchmark FAISS dengan L2 distance\"\"\"\n",
        "    faiss_index = faiss.IndexFlatL2(dim)\n",
        "\n",
        "    start = time.time()\n",
        "    faiss_index.add(X)\n",
        "    build_time = time.time() - start\n",
        "\n",
        "    start = time.time()\n",
        "    distances, indices = faiss_index.search(query, k)\n",
        "    query_time = time.time() - start\n",
        "\n",
        "    return build_time, query_time, indices[0][:5]\n",
        "\n",
        "def benchmark_hnsw(X, query, k, dim, ef_construction=200, M=16, ef=50):\n",
        "    \"\"\"Benchmark HNSW dengan L2 distance\"\"\"\n",
        "    hnsw_index = hnswlib.Index(space='l2', dim=dim)\n",
        "\n",
        "    start = time.time()\n",
        "    hnsw_index.init_index(max_elements=len(X), ef_construction=ef_construction, M=M)\n",
        "    hnsw_index.add_items(X)\n",
        "    build_time = time.time() - start\n",
        "\n",
        "    hnsw_index.set_ef(ef)\n",
        "\n",
        "    start = time.time()\n",
        "    labels, distances = hnsw_index.knn_query(query, k=k)\n",
        "    query_time = time.time() - start\n",
        "\n",
        "    return build_time, query_time, labels[0][:5]\n",
        "\n",
        "# Konfigurasi eksperimen\n",
        "configs = [\n",
        "    (1000, 2),    # 1000 data, 2D\n",
        "    (1000, 5),    # 1000 data, 5D\n",
        "    (1000000, 2), # 1M data, 2D\n",
        "    (1000000, 5), # 1M data, 5D\n",
        "]\n",
        "\n",
        "k = 10\n",
        "results = []\n",
        "\n",
        "print(\"=== EKSPERIMEN PERBANDINGAN PERFORMANCE ANN, FAISS, HNSW ===\\n\")\n",
        "\n",
        "for n_data, dim in configs:\n",
        "    print(f\"Testing: {n_data:,} data, {dim}D\")\n",
        "\n",
        "    # Generate data\n",
        "    np.random.seed(42)  # Untuk reproducibility\n",
        "    X = np.random.random((n_data, dim)).astype(np.float32)\n",
        "    query = np.random.random((1, dim)).astype(np.float32)\n",
        "\n",
        "    # Benchmark masing-masing algoritma\n",
        "    print(\"  Running Annoy...\")\n",
        "    annoy_build, annoy_query, annoy_neighbors = benchmark_annoy(X, query, k, dim)\n",
        "\n",
        "    print(\"  Running FAISS...\")\n",
        "    faiss_build, faiss_query, faiss_neighbors = benchmark_faiss(X, query, k, dim)\n",
        "\n",
        "    print(\"  Running HNSW...\")\n",
        "    hnsw_build, hnsw_query, hnsw_neighbors = benchmark_hnsw(X, query, k, dim)\n",
        "\n",
        "    # Simpan hasil\n",
        "    results.append({\n",
        "        'config': f\"{n_data:,}/{dim}D\",\n",
        "        'annoy_build': annoy_build,\n",
        "        'annoy_query': annoy_query,\n",
        "        'faiss_build': faiss_build,\n",
        "        'faiss_query': faiss_query,\n",
        "        'hnsw_build': hnsw_build,\n",
        "        'hnsw_query': hnsw_query,\n",
        "        'annoy_neighbors': annoy_neighbors,\n",
        "        'faiss_neighbors': faiss_neighbors,\n",
        "        'hnsw_neighbors': hnsw_neighbors\n",
        "    })\n",
        "\n",
        "    print(f\"  Completed: {n_data:,} data, {dim}D\\n\")\n",
        "\n",
        "# Buat tabel hasil\n",
        "df_results = pd.DataFrame(results)\n",
        "print(\"=\"*80)\n",
        "print(\"HASIL PERBANDINGAN PERFORMANCE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "# Tabel Build Time\n",
        "print(\"\\nBUILD TIME (detik):\")\n",
        "build_table = pd.DataFrame({\n",
        "    'Jumlah Data/Dimensi': df_results['config'],\n",
        "    'ANNOY': [f\"{x:.4f}s\" for x in df_results['annoy_build']],\n",
        "    'FAISS': [f\"{x:.4f}s\" for x in df_results['faiss_build']],\n",
        "    'HNSW': [f\"{x:.4f}s\" for x in df_results['hnsw_build']]\n",
        "})\n",
        "print(build_table.to_string(index=False))\n",
        "\n",
        "# Tabel Query Time\n",
        "print(\"\\nQUERY TIME (detik):\")\n",
        "query_table = pd.DataFrame({\n",
        "    'Jumlah Data/Dimensi': df_results['config'],\n",
        "    'ANNOY': [f\"{x:.6f}s\" for x in df_results['annoy_query']],\n",
        "    'FAISS': [f\"{x:.6f}s\" for x in df_results['faiss_query']],\n",
        "    'HNSW': [f\"{x:.6f}s\" for x in df_results['hnsw_query']]\n",
        "})\n",
        "print(query_table.to_string(index=False))\n",
        "\n",
        "# Analisis tambahan\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"ANALISIS:\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for i, result in enumerate(results):\n",
        "    print(f\"\\nKonfigurasi: {result['config']}\")\n",
        "    print(f\"Build Time Tercepat: {min(result['annoy_build'], result['faiss_build'], result['hnsw_build']):.4f}s\")\n",
        "    print(f\"Query Time Tercepat: {min(result['annoy_query'], result['faiss_query'], result['hnsw_query']):.6f}s\")\n",
        "\n",
        "    # Cek konsistensi hasil (5 neighbor teratas)\n",
        "    print(\"5 Neighbor Teratas:\")\n",
        "    print(f\"  Annoy: {result['annoy_neighbors']}\")\n",
        "    print(f\"  FAISS: {result['faiss_neighbors']}\")\n",
        "    print(f\"  HNSW:  {result['hnsw_neighbors']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tugas 2**\n",
        "\n",
        "Lakukan percobaan penggunaan ANNOY, FAISS, dan HNSWLIB pada dataset sekunder berukuran besar (Micro Spotify) pada link berikut: https://www.kaggle.com/datasets/bwandowando/spotify-songs-with-attributes-and-lyrics/data .\n",
        "\n",
        "Download data dan load CSV filenya (pilih dataset yg pertama dari dua dataset).\n",
        "* Pilih hanya fitur numerik saja, dan lakukan normalisasi menggunakan StandardScaler.\n",
        "* Lakukan pencarian track terdekat dan bandingkan hasilnya.\n",
        "* Lakkan perbandingan pada exact NN, ANNOY, FAISS, dan HNSW"
      ],
      "metadata": {
        "id": "H-AiHc4SP3Fg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install kagglehub[panda-datasets]"
      ],
      "metadata": {
        "id": "Owstt5xqENAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install kagglehub[pandas-datasets]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oG1GyvIsBAuR",
        "outputId": "cc208b26-ec79-4ea7-f08f-8611ac8c1771"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: kagglehub[pandas-datasets] in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from kagglehub[pandas-datasets]) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->kagglehub[pandas-datasets]) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub[pandas-datasets]) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->kagglehub[pandas-datasets]) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boilerplate"
      ],
      "metadata": {
        "id": "ufKlzrtzER4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies as needed:\n",
        "# pip install kagglehub[pandas-datasets]\n",
        "import kagglehub\n",
        "from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "# Set the path to the file you'd like to load\n",
        "file_path = \"songs_with_attributes_and_lyrics.csv\"\n",
        "\n",
        "# Load the latest version\n",
        "df = kagglehub.load_dataset(\n",
        "  KaggleDatasetAdapter.PANDAS,\n",
        "  \"bwandowando/spotify-songs-with-attributes-and-lyrics\",\n",
        "  file_path,\n",
        ")\n",
        "\n",
        "print(\"First 5 records:\", df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhwKyJzN9pE3",
        "outputId": "58b0e747-f37f-418f-9e88-c137f31e8f10"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-797073249.py:10: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.\n",
            "  df = kagglehub.load_dataset(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Colab cache for faster access to the 'spotify-songs-with-attributes-and-lyrics' dataset.\n",
            "First 5 records:                        id             name  \\\n",
            "0  0Prct5TDjAnEgIqbxcldY9                !   \n",
            "1  2ASl4wirkeYm3OWZxXKYuq               !!   \n",
            "2  69lcggVPmOr9cvPx9kLiiN  !!! - Interlude   \n",
            "3  4U7dlZjg1s9pjdppqZy0fm   !!De Repente!!   \n",
            "4  4v1IBp3Y3rpkWmWzIlkYju   !!De Repente!!   \n",
            "\n",
            "                               album_name       artists  danceability  energy  \\\n",
            "0                              UNDEN!ABLE  ['HELLYEAH']         0.415  0.6050   \n",
            "1                                     NaN       Yxngxr1         0.788  0.6480   \n",
            "2                       Where I Belong EP    ['Glowie']         0.000  0.0354   \n",
            "3  Un Palo Al Agua (20 Grandes Canciones)   ['Rosendo']         0.657  0.8820   \n",
            "4                          Fuera De Lugar   ['Rosendo']         0.659  0.8930   \n",
            "\n",
            "  key  loudness mode  speechiness  acousticness  instrumentalness  liveness  \\\n",
            "0   7   -11.157    1       0.0575       0.00116          0.838000    0.4710   \n",
            "1   7    -9.135    0       0.3150       0.90000          0.000000    0.1760   \n",
            "2   7   -20.151    0       0.0000       0.90800          0.000000    0.4790   \n",
            "3   5    -6.340    1       0.0385       0.00740          0.000013    0.0474   \n",
            "4   5    -8.531    1       0.0411       0.09220          0.000019    0.0534   \n",
            "\n",
            "   valence    tempo  duration_ms  \\\n",
            "0    0.193  100.059      79500.0   \n",
            "1    0.287   79.998     114000.0   \n",
            "2    0.000    0.000      11413.0   \n",
            "3    0.939  123.588     198173.0   \n",
            "4    0.951  123.600     199827.0   \n",
            "\n",
            "                                              lyrics  \n",
            "0  He said he came from Jamaica,\\n he owned a cou...  \n",
            "1  Fucked a bitch, now she running with my kids\\n...  \n",
            "2                     Oh, my God, I'm going crazy\\n   \n",
            "3  Continuamente se extra√±a la gente si no puede ...  \n",
            "4  Continuamente se extra√±a la gente si no puede ...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "features = ['danceability', 'energy', 'loudness', 'speechiness',\n",
        "            'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']\n",
        "X = df[features].values\n",
        "\n",
        "# Normalisasi data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "k = 10\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdA81p-gCAvM",
        "outputId": "fa39f10f-13a6-43de-d54d-e730c9aed585"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 955320 entries, 0 to 955319\n",
            "Data columns (total 17 columns):\n",
            " #   Column            Non-Null Count   Dtype  \n",
            "---  ------            --------------   -----  \n",
            " 0   id                955320 non-null  object \n",
            " 1   name              955309 non-null  object \n",
            " 2   album_name        385557 non-null  object \n",
            " 3   artists           955318 non-null  object \n",
            " 4   danceability      955320 non-null  float64\n",
            " 5   energy            955320 non-null  float64\n",
            " 6   key               955320 non-null  object \n",
            " 7   loudness          955320 non-null  float64\n",
            " 8   mode              955320 non-null  object \n",
            " 9   speechiness       955320 non-null  float64\n",
            " 10  acousticness      955320 non-null  float64\n",
            " 11  instrumentalness  955320 non-null  float64\n",
            " 12  liveness          955320 non-null  float64\n",
            " 13  valence           955320 non-null  float64\n",
            " 14  tempo             955320 non-null  float64\n",
            " 15  duration_ms       955320 non-null  float64\n",
            " 16  lyrics            955307 non-null  object \n",
            "dtypes: float64(10), object(7)\n",
            "memory usage: 123.9+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split data menjadi corpus dan query"
      ],
      "metadata": {
        "id": "mVBVwXKYEXY7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# split data menjadi query dan corpus\n",
        "np.random.seed(42)\n",
        "n_samples = X_scaled.shape[0]\n",
        "n_queries = 95\n",
        "query_indices = np.random.choice(n_samples, n_queries, replace=False)\n",
        "queries = X_scaled[query_indices]\n",
        "corpus = X_scaled"
      ],
      "metadata": {
        "id": "-puja--tCv7y"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat fungsi hitung recall"
      ],
      "metadata": {
        "id": "yKGXvnueEZ1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recall_at_k(true_idx, pred_idx, k):\n",
        "    recalls = []\n",
        "    for i in range(len(true_idx)):\n",
        "        true_set = set(true_idx[i, :k])\n",
        "        pred_set = set(pred_idx[i, :k])\n",
        "        recalls.append(len(true_set & pred_set) / k)\n",
        "    return np.mean(recalls)"
      ],
      "metadata": {
        "id": "Nioc0TDYCyzw"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perbandingan pada exact NN, ANNOY, FAISS, dan HNSW"
      ],
      "metadata": {
        "id": "k2eC2uLTEcbs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# Exact Nearest Neighbors (NN)\n",
        "# -------------------------------\n",
        "print(\"=== Exact Nearest Neighbors (NN) ===\")\n",
        "t0 = time.time()\n",
        "nn = NearestNeighbors(n_neighbors=k, metric='euclidean')\n",
        "nn.fit(corpus)\n",
        "build_time = time.time() - t0\n",
        "\n",
        "t0 = time.time()\n",
        "dist_exact, idx_exact = nn.kneighbors(queries)\n",
        "query_time = time.time() - t0\n",
        "print(f\"Build time: {build_time:.4f} s, Query time: {query_time:.4f} s\")\n",
        "\n",
        "\n",
        "# -------------------------------\n",
        "# Annoy\n",
        "# -------------------------------\n",
        "print(\"\\n=== Annoy ===\")\n",
        "dims = corpus.shape[1]\n",
        "annoy_idx = AnnoyIndex(dims, 'euclidean')\n",
        "\n",
        "t0 = time.time()\n",
        "for i, vec in enumerate(corpus):\n",
        "    annoy_idx.add_item(i, vec)\n",
        "annoy_idx.build(50) # jumlah tree\n",
        "build_time_annoy = time.time() - t0\n",
        "\n",
        "t0 = time.time()\n",
        "idx_annoy = []\n",
        "for q in queries:\n",
        "    idx_annoy.append(annoy_idx.get_nns_by_vector(q, k))\n",
        "query_time_annoy = time.time() - t0\n",
        "idx_annoy = np.array(idx_annoy)\n",
        "print(f\"Build time: {build_time_annoy:.4f} s, Query time: {query_time_annoy:.4f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# FAISS\n",
        "# -------------------------------\n",
        "print(\"\\n=== FAISS ===\")\n",
        "d = corpus.shape[1]\n",
        "index_faiss = faiss.IndexFlatL2(d)\n",
        "t0 = time.time()\n",
        "index_faiss.add(corpus.astype(np.float32))\n",
        "build_time_faiss = time.time() - t0\n",
        "\n",
        "t0 = time.time()\n",
        "dist_faiss, idx_faiss = index_faiss.search(queries.astype(np.float32), k)\n",
        "query_time_faiss = time.time() - t0\n",
        "print(f\"Build time: {build_time_faiss:.4f} s, Query time: {query_time_faiss:.4f} s\")\n",
        "\n",
        "# -------------------------------\n",
        "# HNSW\n",
        "# -------------------------------\n",
        "print(\"\\n=== HNSW ===\")\n",
        "dim = corpus.shape[1]\n",
        "num_elements = corpus.shape[0]\n",
        "\n",
        "p = hnswlib.Index(space='l2', dim=dim)\n",
        "t0 = time.time()\n",
        "p.init_index(max_elements=num_elements, ef_construction=200, M=32)\n",
        "p.add_items(corpus, np.arange(num_elements))\n",
        "build_time_hnsw = time.time() - t0\n",
        "\n",
        "p.set_ef(50)  # trade-off antara kecepatan dan akurasi\n",
        "t0 = time.time()\n",
        "idx_hnsw, dist_hnsw = p.knn_query(queries, k=k)\n",
        "query_time_hnsw = time.time() - t0\n",
        "print(f\"Build time: {build_time_hnsw:.4f} s, Query time: {query_time_hnsw:.4f} s\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# üîç Evaluasi Recall@k\n",
        "# -----------------------------------------\n",
        "print(\"\\n=== Recall@k Comparison ===\")\n",
        "rec_annoy = recall_at_k(idx_exact, idx_annoy, k)\n",
        "rec_faiss = recall_at_k(idx_exact, idx_faiss, k)\n",
        "rec_hnsw = recall_at_k(idx_exact, idx_hnsw, k)\n",
        "\n",
        "print(f\"Annoy Recall@{k}: {rec_annoy:.4f}\")\n",
        "print(f\"FAISS Recall@{k}: {rec_faiss:.4f}\")\n",
        "print(f\"HNSW Recall@{k}: {rec_hnsw:.4f}\")\n",
        "\n",
        "# -----------------------------------------\n",
        "# üßæ Summary Table\n",
        "# -----------------------------------------\n",
        "summary = pd.DataFrame({\n",
        "    'Method': ['Exact NN', 'Annoy', 'FAISS', 'HNSWLIB'],\n",
        "    'Build Time (s)': [build_time, build_time_annoy, build_time_faiss, build_time_hnsw],\n",
        "    'Query Time (s)': [query_time, query_time_annoy, query_time_faiss, query_time_hnsw],\n",
        "    f'Recall@{k}': [1.0, rec_annoy, rec_faiss, rec_hnsw]\n",
        "})\n",
        "\n",
        "print(\"\\n=== SUMMARY ===\")\n",
        "print(summary.to_string(index=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUb7tmE-C3Gu",
        "outputId": "d7de67da-462c-47e8-eead-1ecc3582e039"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Exact Nearest Neighbors (NN) ===\n",
            "Build time: 7.4345 s, Query time: 0.0816 s\n",
            "\n",
            "=== Annoy ===\n",
            "Build time: 77.2724 s, Query time: 0.0260 s\n",
            "\n",
            "=== FAISS ===\n",
            "Build time: 0.0394 s, Query time: 0.3187 s\n",
            "\n",
            "=== HNSW ===\n",
            "Build time: 208.7090 s, Query time: 0.0053 s\n",
            "\n",
            "=== Recall@k Comparison ===\n",
            "Annoy Recall@10: 0.9853\n",
            "FAISS Recall@10: 0.9926\n",
            "HNSW Recall@10: 0.9937\n",
            "\n",
            "=== SUMMARY ===\n",
            "  Method  Build Time (s)  Query Time (s)  Recall@10\n",
            "Exact NN        7.434536        0.081604   1.000000\n",
            "   Annoy       77.272350        0.025984   0.985263\n",
            "   FAISS        0.039402        0.318670   0.992632\n",
            " HNSWLIB      208.709033        0.005339   0.993684\n"
          ]
        }
      ]
    }
  ]
}